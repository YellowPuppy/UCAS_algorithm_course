\documentclass{article}

\usepackage{xeCJK}
\usepackage{amsfonts}
\usepackage{amssymb}

\title{神经网络增强的动态规划算法及其在求解NP-难问题中的应用}
\author{}
\date{}

\begin{document}

\maketitle

\section{导引}
动态规划 (Dynamic Programming, DP) 是求解组合优化问题的有力工具.
利用问题的最优子结构和重复子问题的性质, 动态规划算法可以显著减小搜索空间和高效找出问题的最优解.
然而, 动态规划算法并非总能奏效.
在求解某些 NP-难的问题时, 动态规划的表格化方法可能需要指数大小的空间和时间.
例如, Held-Karp 算法是求解旅行商问题 (Travelling Salesman Problem, TSP) 的动态规划算法.
其时间复杂度和空间复杂度分别为 $O(2^nn^2)$ 和 $O(2^nn)$.
尽管该方法已经比暴力枚举的 $O(n!)$ 算法要高效不少, 但由于它的指数复杂度, 该算法仍不能解决规模稍大的实际问题.

近年来, 基于神经网络的深度学习在众多领域都取得了巨大的成功.
受神经网络强大的近似性能和灵活性启发, 本文中, 我们提出使用神经网络来近似代替表格化方法中的表格来实现动态规划算法.
我们的方法有若干优势.
首先, 我们的方法比传统的表格化方法大大减小了问题求解所需要的空间.
由于神经网络的近似性和灵活性, 我们使用一个规模小得多的神经网络来近似代替原来的表格.
其次, 比起已有的端到端的利用神经网络求解组合优化的方案, 我们的方法充分利用了原问题的本质特性, 即最优子结构和重复子问题性质, 所求得的解具有较高质量.

然而, 如何训练该神经网络是一个巨大的挑战.
在经典监督学习中, 我们使用大量标注数据来训练一个神经网络.
但是在求解组合优化问题中, 哪怕精确计算一条标注数据都是一个 NP-难问题.
为此, 我们设计了一个迭代更新的算法来训练该神经网络.
我们利用动态规划方程的递归性质, 使神经网络的训练目标变为直接近似相应的动态规划方程.

我们将该方法应用于求解 TSP 问题.
实验结果显示, 我们的方法能求解的问题规模显著大于传统的 Held-Karp 动态规划算法.
而且我们的方法求得的解接近于最优解, 优于若干知名的近似算法.

\section{方法}

我们首先简要回顾动态规划方法.
动态规划可看作一个多步决策过程. 
在每一步, 我们面对一个子问题.
当我们对当前子问题做出一步决策后, 我们将面对一些更小的子问题.
面对的子问题有时也称为状态.
动态规划的基本思想是计算一个状态函数 $f: \mathcal{S} \to \mathbb{R}$, 其中 $\mathcal{S}$ 为状态集.
函数 $f$ 将一个状态映射为该子问题的最优值.
最优子结构性质意味着一个问题的解可以通过其子问题的解来构造.
因此, 我们可以通过一个自顶向下的递归方程来描述该关系.
对状态 $s \in \mathcal{S}$, 假设我们做出决策 $a$ 以后可导致子状态集合 $\delta(s, a)$, 那么最小化问题的动态规划方程一般具有如下形式:
\begin{equation} \label{eqn_1}
f(s) = \min_a \left\{v(a) + \sum_{s' \in \delta(s, a)}f(s')\right\},
\end{equation}
其中 $a$ 遍历状态 $s$ 下所有可行的决策而 $v(a)$ 为做出决策 $a$ 所消耗的代价.
由于重复子问题性质, 我们不必要每次重新计算 $f(s)$, 而是将已经计算好的 $f(s)$ 存储于一个表格中, 若求解其他子问题时仍需要计算 $f(s)$, 直接查表即可. 
此即动态规划的表格化方法.

尽管动态规划的表格化方法对很多组合优化问题有效. 
但对某些 NP-难问题, 表格化方法需要指数规模的空间, 如上述的 Held-Karp 算法.
然而, 表格并非是表示和存储函数的唯一选择.
神经网络也是表示函数的重要手段, 而且神经网络具有强大的近似性和灵活性.
因此, 我们提出使用神经网络来代替表格化方法.
而我们使用的神经网络具有较小的规模, 其大小仅与原问题的规模成多项式关系.
为什么具有较小规模的神经网络也可以很好地表示动态规划函数? 我们认为: 
首先, 动态规划函数不需要绝对精确. 其只是用来构造最优解的工具, 而解的值可以直接计算.
其次, 并非所有的状态都是同样重要的. 我们可以令重要的状态具有较高的精度, 而不重要的状态的精度可以差一点.
也就是说, 神经网络不必要一致拟合所有的状态.
再次, 在实际应用中, 次优解往往足够.
即使神经网络表示的动态规划函数不甚精确, 但只要它能高效地求得次优解, 也是十分有价值的.

在解决了表示和存储的问题以后, 如何训练该神经网络成为了一大挑战.
在传统的机器学习(监督学习)中, 我们使用大量的标注数据来训练神经网络.
然而, 在求解 NP-难的组合优化问题中, 即使计算一个标注数据, 也需要指数的时间.
注意到动态规划函数具有递归特性, 与其让神经网络拟合大量标注数据, 我们转向寻求让该神经网络尽可能地符合该递归关系.
具体而言, 假设 $f(s; \theta)$ 是该神经网络, 其中 $s$ 为输入状态的向量表示, $\theta$ 为神经网络的模型参数.
在理想情况下, 若 $f$ 正好是所求得动态规划函数, 那么方程 (\ref{eqn_1}) 对所有状态都满足. 
然而, 方程左右两项通常会有差异.
一个自然的想法是通过调整模型参数 $\theta$, 使得左右两边的差异尽可能地小.
因此我们的训练目标变为最小化如下目标函数,
\begin{equation}
J(\theta) = \sum_{s \in \mathcal{S}}\left(f(s;\theta) - \min_a\left\{v(a) + \sum_{s' \in \delta(s, a)}f(s'; \theta)\right\}\right)^2.
\end{equation}
然而, 由于 $\mathcal{S}$ 具有指数多的状态, 直接使用梯度下降法等方法来优化该目标函数是不实际的.
因此, 类似于随机梯度下降法, 我们使用采样的方法来优化该目标函数. 我们设计了如下的采样策略: 
假设当前的 $f(s; \theta_t)$ 是我们所求的动态规划函数. 
基于它我们可以构造一个解, 该解由一系列状态组成. 
为提高探索的效率, 在构造解的时候, 我们加入了一定的随机性. 这些状态则为我们用来优化上述目标函数的数据.
基于这些采样得到的状态, 我们将梯度下降法应用于这些数据中, 将模型参数更新为 $\theta_{t+1}$:
\begin{equation}
\theta_{t+1} = \theta_t - \eta_t\widetilde{\nabla}J(\theta_t).
\end{equation}

\section{实验}

我们将我们的方法应用于求解 TSP 问题中.
%我们将我们的方法命名为 
我们在 TSP 问题的经典数据集 TSPLIB 上进行实验, 其中包含对称和非对称的 TSP 问题实例. 
我们实现了 4 个算法. 
第一个是我们的算法, 命名为 NNDP (Neural Network Dynamic Programmming).
第二个为 Held-Karp 算法, 即传统的表格化动态规划算法.
第三个为著名的近似算法 Christofides 算法. 
该算法具有最优的理论近似比保证, 但它只能应用于对称图中.
最后一个为最近邻贪心算法. 
这也是一个著名的近似算法, 而且它非常简单且具有非常高的效率.

实验的结果列举于表格 \ref{tab} 中. 
数据实例名字后面的数字为问题规模, 即图的节点数.
前7个数据为对称 TSP 实例, 而后 3 个数据为非对称 TSP 实例.
对每个算法作用于每个数据点的结果, 我既给出了解的绝对大小, 也给出了它相对于最优解的比率.

从实验结果来看, 尽管 Held-Karp 算法能保证最优解, 但由于它的空间复杂性问题, 不能扩展到相对大的问题实例中. 
我们的算法克服了该空间问题, 从而能求解规模大得多的问题实例.

我们的解也具有较好的质量, 相对误差基本在 $10\%$ 以内, 优于 Christofides 算法和最近邻贪心算法. 

% data | optimal | NN | Held-Karp | Christofides | Greedy |
\begin{table*}[htbp] %tbp
	\centering
	\caption{Experimental results in TSPLIB}
	\label{tab}
	\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|}
		\hline
		\textbf{Data} & \textbf{Best} & \multicolumn{2}{|c|}{\textbf{NNDP}} & \multicolumn{2}{|c|}{\textbf{Held-Karp}} & \multicolumn{2}{|c|}{\textbf{Christofides}} &  \multicolumn{2}{|c|}{\textbf{Greedy}}\\
		\hline
		Gr17 & 2085 & \textbf{2085} & \textbf{1} & \textbf{2085} & \textbf{1} & 2287 & 1.1607 & 2178 & 1.0446\\
		\hline
		Bayg29 & 1610 & \textbf{1610} & \textbf{1} & NA & NA & 1737 & 1.0789 & 1935 & 1.2019\\
		\hline
		Dantzig42 & 699 & \textbf{709} & \textbf{1.0143} & NA & NA & 966 & 1.382 & 863 & 1.2346\\
		\hline
		HK48 & 11461 & \textbf{11539} & \textbf{1.0068} & NA & NA & 13182 & 1.1502 & 12137 & 1.059\\
		\hline
		Att48 & 10628 & \textbf{10868} & \textbf{1.0226} & NA & NA & 15321 & 1.4416 & 12012 & 1.1302\\
		\hline
		Eil76 & 538 & \textbf{585} & \textbf{1.0874} & NA & NA & 651 & 1.1128 & 598 & 1.1115\\
		\hline
		Rat99 & 1211 & \textbf{1409} & \textbf{1.1635} & NA & NA & 1665 & 1.3749 & 1443 & 1.1916\\
		\hline
		\multicolumn{10}{|c|}{}\\
		\hline
		Br17 & 39 & \textbf{39} & \textbf{1} & \textbf{39} & \textbf{1} & NA & NA & 56 & 1.435\\
		\hline
		Ftv33 & 1286 & \textbf{1324} & \textbf{1.0295} & NA & NA & NA & NA & 1589 & 1.2002\\
		\hline
		Ft53 & 6905 & \textbf{7343} & \textbf{1.0634} & NA & NA & NA & NA & 8584 & 1.169\\
		\hline
	\end{tabular}
\end{table*}

\end{document}
